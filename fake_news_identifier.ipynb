{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "m1m9qnCWJSN_",
        "mMtf_agbIzFx",
        "2xXLIbm3I7MS",
        "Z6NhTYBoJGSb"
      ],
      "authorship_tag": "ABX9TyPDsIQ/LMeAf95npCIgYlig",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adarshm11/fake-news-identifier/blob/main/fake_news_identifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fake News Identifier\n"
      ],
      "metadata": {
        "id": "-2_pX0ApIX-6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fake news runs rampant in today's society, and in the age of artificial intelligence, it can be difficult to separate what is real from what is false. However, we can use the power of data and machine learning to assess whether news is authentic or not, which is what this project attempts to accomplish."
      ],
      "metadata": {
        "id": "ELWFER6mIkmK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "m1m9qnCWJSN_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Setup Google Colab and Sync with GitHub"
      ],
      "metadata": {
        "id": "mMtf_agbIzFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!apt-get install git\n",
        "!git clone https://github.com/adarshm11/fake-news-identifier.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6rJa3E1GDam",
        "outputId": "18a39142-1331-409a-d9db-cc633ce58fbf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.11).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "fatal: destination path 'fake-news-identifier' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Setup Kaggle Connection"
      ],
      "metadata": {
        "id": "2xXLIbm3I7MS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QIonfqED4tx3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "outputId": "33e6a9b4-4ca0-42dd-fb73-f9e4d83210f5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1fa2e820-8536-4e70-a7a5-2aaed1ad5cef\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1fa2e820-8536-4e70-a7a5-2aaed1ad5cef\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "ref                                                         title                                             size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "----------------------------------------------------------  -----------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "bhadramohit/customer-shopping-latest-trends-dataset         Customer Shopping (Latest Trends) Dataset         76KB  2024-11-23 15:26:12          19177        377  1.0              \n",
            "hopesb/student-depression-dataset                           Student Depression Dataset.                      454KB  2024-11-22 17:56:03          15685        222  1.0              \n",
            "oktayrdeki/houses-in-london                                 Houses in London                                  21KB  2024-12-15 19:27:42           1420         27  1.0              \n",
            "mhassansaboor/intel-stock-data-1980-2024                    Intel Stock Data (1980-2024)                     281KB  2024-12-25 16:12:36            658         24  1.0              \n",
            "govindaramsriram/sleep-time-prediction                      Sleep Time Prediction                             28KB  2024-12-28 17:08:56            880         25  1.0              \n",
            "michaellanurias/spotify-playlist-origins                    Spotify Playlist-ORIGINS                          25KB  2024-12-15 01:16:34            907         22  1.0              \n",
            "kanchana1990/global-adult-hiv-prevalance-data-2024-updated  Global Adult HIV Prevalance Data (2024 Updated)    3KB  2024-12-28 17:32:21            324         24  1.0              \n",
            "bushraqurban/world-health-indicators-dataset                üè• Global Health Indicators Dataset üìä             186KB  2024-12-22 02:35:39            898         26  1.0              \n",
            "taimoor888/top-100-youtube-channels-in-2024                 Top 100 YouTube Channels in 2024                   3KB  2024-12-15 16:09:25           1182         34  1.0              \n",
            "sezginfurkan/geophone-sensor-dataset                        Geophone Sensor Dataset                           74KB  2024-12-26 18:23:21            323         22  1.0              \n",
            "denkuznetz/food-delivery-time-prediction                    Food Delivery Time Prediction üõµ                   12KB  2024-12-23 13:12:14           1112         35  1.0              \n",
            "mujtabamatin/air-quality-and-pollution-assessment           Air Quality and Pollution Assessment              84KB  2024-12-04 15:29:51           7405        115  1.0              \n",
            "bushraqurban/tourism-and-economic-impact                    ‚úàÔ∏è Tourism and Economic Impact Datasetüí∞          270KB  2024-12-22 08:47:37           1305         34  1.0              \n",
            "kanchana1990/world-internet-usage-data-2023-updated         World Internet Usage Data (2023 Updated)           4KB  2024-12-21 09:41:41            644         43  1.0              \n",
            "rahmasleam/breast-cancer                                    Breast Cancer                                     49KB  2024-12-10 08:44:26           1335         33  1.0              \n",
            "anandshaw2001/chatgpt-users-reviews                         ChatGPT Users Reviews                              9MB  2024-12-26 10:14:42            378         25  1.0              \n",
            "gauthamvijayaraj/spotify-tracks-dataset-updated-every-week  Spotify Tracks Dataset (Updated every week)        5MB  2024-12-09 18:00:01           3192         62  1.0              \n",
            "dansbecker/melbourne-housing-snapshot                       Melbourne Housing Snapshot                       451KB  2018-06-05 12:52:24         167138       1557  0.7058824        \n",
            "denkuznetz/traffic-accident-prediction                      Traffic Accident Prediction üí•üöó                    10KB  2024-12-11 11:04:47           2448         44  1.0              \n",
            "steve1215rogg/e-commerce-dataset                            E-Commerce Dataset                                90KB  2024-11-22 22:10:02           6555         78  1.0              \n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle -q kagglehub\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Import the Kaggle dataset"
      ],
      "metadata": {
        "id": "Z6NhTYBoJGSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install --upgrade kagglehub\n",
        "import kagglehub\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download('saurabhshahane/fake-news-classification')\n",
        "\n",
        "print(os.listdir(path))\n",
        "csv_file = os.path.join(path, 'WELFake_Dataset.csv')\n",
        "df = pd.read_csv(csv_file)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A75X3an8666L",
        "outputId": "dbc19580-2d9a-4f25-807d-16063d3927fc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (0.3.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2024.12.14)\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "['WELFake_Dataset.csv']\n",
            "   Unnamed: 0                                              title  \\\n",
            "0           0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
            "1           1                                                NaN   \n",
            "2           2  UNBELIEVABLE! OBAMA‚ÄôS ATTORNEY GENERAL SAYS MO...   \n",
            "3           3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
            "4           4  SATAN 2: Russia unvelis an image of its terrif...   \n",
            "\n",
            "                                                text  label  \n",
            "0  No comment is expected from Barack Obama Membe...      1  \n",
            "1     Did they post their votes for Hillary already?      1  \n",
            "2   Now, most of the demonstrators gathered last ...      1  \n",
            "3  A dozen politically active pastors came here f...      0  \n",
            "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can read from the dataset, so we know the connection is successful! Now we can download the dataset to our file menu."
      ],
      "metadata": {
        "id": "v197sVvHJaJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Download the Dataset"
      ],
      "metadata": {
        "id": "uYJdaefwKUlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d saurabhshahane/fake-news-classification\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "with zipfile.ZipFile('fake-news-classification.zip', 'r') as zip_file:\n",
        "  zip_file.extractall('data')\n",
        "\n",
        "!ls data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPVVegZ-KZ2L",
        "outputId": "6330d2c6-e00f-4c95-e85c-cfc59faea167"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/saurabhshahane/fake-news-classification\n",
            "License(s): Attribution 4.0 International (CC BY 4.0)\n",
            "fake-news-classification.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "WELFake_Dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Save to Drive"
      ],
      "metadata": {
        "id": "8Yk6fHPPLNXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r data /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "OcDVlgSXLP8U"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "IK9B7aCbLZBx"
      }
    }
  ]
}